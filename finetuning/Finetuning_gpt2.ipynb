{"cells":[{"cell_type":"markdown","source":["# Overview"],"metadata":{"id":"Qy4Rb8IqBA7A"}},{"cell_type":"markdown","source":["**Objective:** Generate text that replicates the stylistic attributes present in Gustavo Adolfo Becquer's books.\n","\n","**Input:** Dataset for finetuning (concatenated books).\n","\n","*   [Legends, Tales, and Poems](https://www.gutenberg.org/ebooks/10814)\n","*   [Obras escogidas](https://www.gutenberg.org/ebooks/53552)\n","\n","**Expected Output:** Finetuned model (.pt file).\n"],"metadata":{"id":"dgW7HClJrGwO"}},{"cell_type":"markdown","source":["This code includes:\n","\n","*   Downloading and preprocessing datasets from gutemberg.org\n","*   Tokenizing and finetuning [gpt2-spanish](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fhuggingface.co%2FDeepESP%2Fgpt2-spanish%3Ftext%3DQuisiera%2Bsaber%2Bque%2Bva%2Ba%2Bsuceder)\n","*   Saving the output model to gdrive\n","\n"],"metadata":{"id":"y1_26MvJ_RW5"}},{"cell_type":"markdown","source":["Follow the code below or [go straight to the results](#conclusion)"],"metadata":{"id":"f4a5B_Au2RfO"}},{"cell_type":"markdown","source":["# Basic imports"],"metadata":{"id":"_pK5kyvlE3yT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXhZDuT6SR3z"},"outputs":[],"source":["!pip install transformers datasets torch\n","!pip install transformers[torch]\n","!pip install accelerate -U"]},{"cell_type":"code","source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments"],"metadata":{"id":"9bc7Xh2u4Rvk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import os\n","import re"],"metadata":{"id":"DFfzKuk39YiT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data cleaning and preprocessing"],"metadata":{"id":"NUvVhWQC9PrV"}},{"cell_type":"code","source":["files_gutemberg = {\n","    \"Leyendas, cuentos y poemas\": { \"file_name\":\"leyendas_cuentos_poemas.txt\",\"url\":\"https://www.gutenberg.org/files/10814/10814-8.txt\",\"encoding\":\"ISO-8859-1\" },\\\n","    \"Obras escogidas\": { \"file_name\":\"obras_escogidas.txt\",\"url\":\"https://www.gutenberg.org/files/53552/53552-8.txt\",\"encoding\":\"ISO-8859-1\" }\n","    }"],"metadata":{"id":"wZdl5IOj9aSt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Doc 1: Leyendas, cuentos y poemas"],"metadata":{"id":"5KLIMTXq0M0A"}},{"cell_type":"code","source":["path = tf.keras.utils.get_file(\"Leyendas, cuentos y poemas\", \"https://www.gutenberg.org/files/10814/10814-8.txt\")\n","text = open(path, \"rb\").read().decode(encoding=\"ISO-8859-1\")\n","print(f\"Leyendas, cuentos y poemas\")\n","print(f\"Length of text: {len(text):,} characters\")\n","print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8oqeQFw69dji","executionInfo":{"status":"ok","timestamp":1696784173049,"user_tz":420,"elapsed":1187,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"3ed45275-ebe4-4e12-9e2b-94ae7a76560f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.gutenberg.org/files/10814/10814-8.txt\n","698992/698992 [==============================] - 0s 1us/step\n","Leyendas, cuentos y poemas\n","Length of text: 698,992 characters\n","\n"]}]},{"cell_type":"code","source":["# Remove anything before the first sentence of the book.\n","sequence = \"(_Cartas Literarias_)\"\n","\n","# Split the string based on the sequence\n","split_result = text.split(sequence, 1) # splits just 1 time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[1].lstrip()\n","else:\n","    result_string = text"],"metadata":{"id":"eK7vrvVC9q8h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove anything after the last sentence of the book.\n","sequence = \"Á quienes no conozco!\"\n","\n","# Split the string based on the sequence\n","split_result = result_string.split(sequence, 1) # splits just one time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[0]\n","else:\n","    result_string = text"],"metadata":{"id":"CHQs2oek9xUL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove footnotes in English (text inside brackets).\n","\n","# Use regular expressions to remove text inside brackets\n","cleaned_document = re.sub(r'\\[.*?\\]', '', result_string, flags=re.DOTALL)\n","\n","# Print the cleaned document\n","print(cleaned_document)\n"],"metadata":{"id":"ZJbXwk4kicGw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(cleaned_document)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HxlAy9bp91jz","executionInfo":{"status":"ok","timestamp":1696784173050,"user_tz":420,"elapsed":53,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"de870ad0-bd68-4376-ff06-9098d4ef3144"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Get the current working directory\n","current_directory = os.getcwd()\n","\n","# Print the current working directory\n","print(\"Current working directory:\", current_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpbhReV3_JUt","executionInfo":{"status":"ok","timestamp":1696784173050,"user_tz":420,"elapsed":6,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"43032fea-2fcb-4bcf-a665-738566d66888"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content\n"]}]},{"cell_type":"code","source":["# Save file in the working directory\n","\n","# Specify the file path where you want to save the file\n","file_path = \"gutemberg_cuentos_leyendas.txt\"\n","\n","# Open the file in write mode ('w')\n","with open(file_path, 'w') as file:\n","    # Write the string to the file\n","    file.write(cleaned_document)\n","\n","# The file is automatically closed when the 'with' block exits\n"],"metadata":{"id":"ctmIfS02_TTx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Doc 2: Obras escogidas"],"metadata":{"id":"dMCgn1HR0UWd"}},{"cell_type":"code","source":["path = tf.keras.utils.get_file(\"Obras escogidas\", \"https://www.gutenberg.org/files/53552/53552-8.txt\")\n","text = open(path, \"rb\").read().decode(encoding=\"ISO-8859-1\")\n","print(f\"Obras escogidas\")\n","print(f\"Length of text: {len(text):,} characters\")\n","print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696784173737,"user_tz":420,"elapsed":432,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"560e362c-1d42-4dac-fbc3-652e6a782753","id":"Vznyp7bT0bdz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.gutenberg.org/files/53552/53552-8.txt\n","585523/585523 [==============================] - 0s 1us/step\n","Obras escogidas\n","Length of text: 585,523 characters\n","\n"]}]},{"cell_type":"code","source":["# Original text with new lines\n","original_text = \"el monumento erigido al\\npoeta.\"\n","\n","# Convert new lines to ISO-8859-1 encoding with appropriate newline character\n","iso_8859_1_text = original_text.encode('iso-8859-1').replace(b'\\n', b'\\r\\n')\n","  # replace(b'\\n', b'\\r\\n') replaces the newline character (b'\\n') with the Windows-style newline character (b'\\r\\n').\n","  # Adjust the replacement value according to the desired newline character format.\n","\n","# Print the encoded text\n","print(iso_8859_1_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"se0lHZ6M4BGt","executionInfo":{"status":"ok","timestamp":1696784173737,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"505a3334-ce59-432a-850b-1c9feaae1641"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b'el monumento erigido al\\r\\npoeta.'\n"]}]},{"cell_type":"code","source":["substring = \"el monumento erigido al\\r\\npoeta.\"\n","\n","if substring in text:\n","    print(\"Substring found!\")\n","else:\n","    print(\"Substring not found.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMXKg6L93pJl","executionInfo":{"status":"ok","timestamp":1696784173737,"user_tz":420,"elapsed":4,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"09f0e733-458c-4bbf-ea91-d8cd07c2eb71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Substring found!\n"]}]},{"cell_type":"code","source":["# Remove anything before the first sentence of the book.\n","sequence = \"el monumento erigido al\\r\\npoeta.\"\n","\n","# Split the string based on the sequence\n","split_result = text.split(sequence, 1) # splits just 1 time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[1].lstrip()\n","else:\n","    result_string = text"],"metadata":{"id":"WCgEf-s_0bd0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result_string)"],"metadata":{"id":"s7oRyN1a2hUx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove anything after the last sentence of the book.\n","sequence = \"creo que le sucedería lo mismo.\" # Not including the 'Rimas' section.\n","\n","# Split the string based on the sequence\n","split_result = result_string.split(sequence, 1) # splits just one time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[0]\n","else:\n","    result_string = text\n","\n"],"metadata":{"id":"hz5K7bfm0bd0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(result_string)"],"metadata":{"id":"RnmCds8V6_3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove editorial comments (in brackets).\n","\n","# Use regular expressions to remove text inside brackets\n","cleaned_document_2 = re.sub(r'\\[.*?\\]', '', result_string, flags=re.DOTALL)\n"],"metadata":{"id":"BbQ6Hwsy0bd6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cleaned_document_2)"],"metadata":{"id":"aDhVwU5p7OfV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove editorial underscores that denote italics, keep text in between.\n","\n","# Remove underscores using str.replace() method\n","cleaned_document_2 = cleaned_document_2.replace(\"_\", \"\")\n","\n","# Print the cleaned string\n","print(cleaned_document_2)\n"],"metadata":{"id":"Hx_R90p01IxL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(cleaned_document_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696784177132,"user_tz":420,"elapsed":104,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"799259e4-6b56-43bf-bad2-10f1d1b74547","id":"RloGWvky0bd6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["# Get the current working directory\n","current_directory = os.getcwd()\n","\n","# Print the current working directory\n","print(\"Current working directory:\", current_directory)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696784177132,"user_tz":420,"elapsed":15,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"fc26c415-bc01-4397-b676-4afdc205782e","id":"wbTzRsE60bd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Current working directory: /content\n"]}]},{"cell_type":"code","source":["# Save file in the working directory to get path\n","\n","# Specify the file path where you want to save the file\n","file_path = \"gutemberg_obras_escogidas.txt\"\n","\n","# Open the file in write mode ('w')\n","with open(file_path, 'w') as file:\n","    # Write the string to the file\n","    file.write(cleaned_document_2)\n","\n","# The file is automatically closed when the 'with' block exits\n"],"metadata":{"id":"yFN2DfL50bd6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Join both datasets"],"metadata":{"id":"2tOO8Aan1qeI"}},{"cell_type":"code","source":["# Two strings to join\n","string1 = cleaned_document\n","string2 = cleaned_document_2\n","\n","# Join the strings together\n","joined_string = string1 + string2\n","\n","# Specify the file path where you want to create the text file\n","file_path = \"gutemberg_joined.txt\"\n","\n","# Open the file in write mode and write the joined string\n","with open(file_path, 'w') as file:\n","    file.write(joined_string)\n","\n","print(\"Text file created successfully.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"frhuj87j8TlK","executionInfo":{"status":"ok","timestamp":1696784177132,"user_tz":420,"elapsed":13,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"8e40e972-847e-4777-f371-f64927aa4be7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text file created successfully.\n"]}]},{"cell_type":"code","source":["print('The total length of both documents is {} characters.'.format(len(joined_string)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O38V3QOw-OiM","executionInfo":{"status":"ok","timestamp":1696784177132,"user_tz":420,"elapsed":12,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}},"outputId":"2250c362-32e6-4c42-8985-e42b290e5a15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The total length of both documents is 750699 characters.\n"]}]},{"cell_type":"markdown","source":["# Finetuning gpt2-spanish"],"metadata":{"id":"oSim_yAlDeVB"}},{"cell_type":"markdown","source":["## Setup to save model in Gdrive"],"metadata":{"id":"s82xSUaIEgul"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"WJUe60eWDdaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /content/gdrive"],"metadata":{"id":"u8IRRtgyD03N","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":6,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","DATADIR = os.path.join('/content/gdrive', 'My Drive', 'XXX', 'XXX', 'XXX') # Replace with your Gdrive folder path"],"metadata":{"id":"9Ts_23-tE3VE","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATADIR"],"metadata":{"id":"gH1tXGkmGhQA","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## About the model"],"metadata":{"id":"3ffvtbcw9Sk7"}},{"cell_type":"markdown","source":["[**DeepESP/gpt2-spanish**](https://huggingface.co/DeepESP/gpt2-spanish?text=Quisiera+saber+que+va+a+suceder)\n","\n","License: [mit](https://choosealicense.com/licenses/mit/)\n","\n","Why is it a good fit for this project?\n","\n","* It was trained on literary text, the writing field of our writer.\n","* The tokenizer was trained from scratch with the Spanish corpus, to capture the morphosyntactic differences between English and Spanish."],"metadata":{"id":"Q-prsHdb_9Dd"}},{"cell_type":"markdown","source":["## Finetuning"],"metadata":{"id":"dSMqbkeRFeiB"}},{"cell_type":"code","source":["# Load model directly with Hugging Face Auto Classes\n","from transformers import AutoTokenizer, AutoModelForCausalLM"],"metadata":{"id":"ML_AknJCeJzA","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Constants\n","MODEL_NAME = \"gpt2-spanish\"\n","TRAIN_FILE = \"gutemberg_joined.txt\"\n","TOKENIZER_FILE = \"tokenizer.json\"\n","OUTPUT_DIR = DATADIR # Going to Gdrive"],"metadata":{"id":"TYd4rwfp4nM-","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the tokenizer and model\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"DeepESP/gpt2-spanish\")\n","model = AutoModelForCausalLM.from_pretrained(\"DeepESP/gpt2-spanish\")\n"],"metadata":{"id":"xIeSXrrV4pcW","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare the dataset\n","train_dataset = TextDataset(\n","    tokenizer = tokenizer,\n","    file_path = TRAIN_FILE,\n","    block_size = 128\n",")\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer = tokenizer,\n","    mlm = False\n",")\n"],"metadata":{"id":"I1dF6Rau5Ay4","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define training arguments and start fine-tuning\n","training_args = TrainingArguments(\n","    output_dir = OUTPUT_DIR,\n","    overwrite_output_dir = False,\n","    per_device_train_batch_size = 8,\n","    num_train_epochs = 1,\n","    save_steps = 10_000,\n","    save_total_limit = 2,\n",")\n","\n","trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    data_collator = data_collator,\n","    train_dataset = train_dataset,\n",")\n","\n","trainer.train()"],"metadata":{"id":"U9NuiqX0VDCZ","executionInfo":{"status":"aborted","timestamp":1698008532522,"user_tz":420,"elapsed":5,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save finetuned model"],"metadata":{"id":"nqcdQaVsL2ND"}},{"cell_type":"markdown","source":["From [How to save our model to google Drive and reuse it](https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2)"],"metadata":{"id":"yZyUIJxxMK97"}},{"cell_type":"code","source":["model_save_name = 'gpt2-spanish_Becquer-joined.pt'\n","path = DATADIR\n","torch.save(model.state_dict(), path)"],"metadata":{"id":"LTgcXx42LUJI","executionInfo":{"status":"aborted","timestamp":1698008532523,"user_tz":420,"elapsed":6,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Use model for text generation"],"metadata":{"id":"7wDrqEKVFZ73"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVWYeD9lSbKD","executionInfo":{"status":"aborted","timestamp":1698008532523,"user_tz":420,"elapsed":6,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"outputs":[],"source":["# Save finetuning files\n","model.save_pretrained(OUTPUT_DIR)\n","\n","print(f\"Model fine-tuned and saved to {OUTPUT_DIR}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TKZbpkjgSb4p","executionInfo":{"status":"aborted","timestamp":1698008532523,"user_tz":420,"elapsed":6,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"}}},"outputs":[],"source":["prompt = \"Será verdad que\"  # Change this to your desired starting prompt\n","max_length = 150  # Change this to desired output length\n","\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","input_ids = input_ids.to(\"cuda\")\n","\n","output = model.generate(input_ids, max_length=max_length, temperature=0.7)\n","output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(output_text)\n"]},{"cell_type":"markdown","source":["<a name=\"conclusion\"></a>\n","# Conclusion"],"metadata":{"id":"72NP9Wi2Hwe8"}},{"cell_type":"markdown","source":["The model was finetuned successfully, but it generates repetitive nonsense--no resemblance to the writing style of our author.\n","\n","For improvements and fixes to the output, see `Decoding_methods-gpt2_finetuned.ipynb`, where I use different decoding methods for language generation with Transformers."],"metadata":{"id":"TGlxZD8lHnwL"}},{"cell_type":"markdown","source":["## Output example"],"metadata":{"id":"6VM8XgpusfbB"}},{"cell_type":"markdown","source":["Prompt:\n","`\"Será verdad que...\"`\n","\n","Output:\n","`Será verdad que no se ha de\n","hablar de la verdad, y que no se ha de\n","haber de la verdad, y que no se ha de\n","haber de la verdad, sino de la verdad, y que\n","se ha de creer que no se ha de creer en nada, y que\n","se ha de creer que no se ha de creer en nada, y que\n","se ha de creer en algo, y que no se ha de creer en nada, y que\n","se ha de creer en algo, y que no se ha de creer en nada, y que\n","se ha de creer en algo, y que no se ha de creer en nada, y que\n","se ha de creer en algo, y que se`"],"metadata":{"id":"ZH1QjkJZJG_Q"}}],"metadata":{"colab":{"gpuType":"T4","provenance":[{"file_id":"1aYS-er_ke6CX454Hx_emodd4OGpOLXG2","timestamp":1695940394581}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}