{"cells":[{"cell_type":"markdown","metadata":{"id":"Qy4Rb8IqBA7A"},"source":["# Overview"]},{"cell_type":"markdown","metadata":{"id":"dgW7HClJrGwO"},"source":["**Objective:** Generate text that replicates the stylistic attributes present in Gustavo Adolfo Becquer's books.\n","\n","**Input:** Dataset for finetuning (concatenated books).\n","\n","*   [Legends, Tales, and Poems](https://www.gutenberg.org/ebooks/10814)\n","*   [Obras escogidas](https://www.gutenberg.org/ebooks/53552)\n","\n","**Expected Output:** Finetuned model (.pt file).\n"]},{"cell_type":"markdown","metadata":{"id":"y1_26MvJ_RW5"},"source":["This code includes:\n","\n","*   Downloading and preprocessing datasets from gutemberg.org\n","*   Tokenizing and finetuning [gpt2-spanish](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fhuggingface.co%2FDeepESP%2Fgpt2-spanish%3Ftext%3DQuisiera%2Bsaber%2Bque%2Bva%2Ba%2Bsuceder)\n","*   Saving the output model to gdrive\n","\n"]},{"cell_type":"markdown","metadata":{"id":"f4a5B_Au2RfO"},"source":["Follow the code below or [go straight to the results](#conclusion)"]},{"cell_type":"markdown","metadata":{"id":"_pK5kyvlE3yT"},"source":["# Basic imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXhZDuT6SR3z"},"outputs":[],"source":["!pip install transformers datasets torch\n","!pip install transformers[torch]\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9bc7Xh2u4Rvk"},"outputs":[],"source":["import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DFfzKuk39YiT"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import os\n","import re"]},{"cell_type":"markdown","metadata":{"id":"NUvVhWQC9PrV"},"source":["# Data cleaning and preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZdl5IOj9aSt"},"outputs":[],"source":["files_gutemberg = {\n","    \"Leyendas, cuentos y poemas\": { \"file_name\":\"leyendas_cuentos_poemas.txt\",\"url\":\"https://www.gutenberg.org/files/10814/10814-8.txt\",\"encoding\":\"ISO-8859-1\" },\\\n","    \"Obras escogidas\": { \"file_name\":\"obras_escogidas.txt\",\"url\":\"https://www.gutenberg.org/files/53552/53552-8.txt\",\"encoding\":\"ISO-8859-1\" }\n","    }"]},{"cell_type":"markdown","metadata":{"id":"5KLIMTXq0M0A"},"source":["## Doc 1: Leyendas, cuentos y poemas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1187,"status":"ok","timestamp":1696784173049,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"8oqeQFw69dji","outputId":"3ed45275-ebe4-4e12-9e2b-94ae7a76560f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.gutenberg.org/files/10814/10814-8.txt\n","698992/698992 [==============================] - 0s 1us/step\n","Leyendas, cuentos y poemas\n","Length of text: 698,992 characters\n","\n"]}],"source":["# Download a file from a URL and store it locally using the Keras library\n","# Print the length, total characters\n","\n","path = tf.keras.utils.get_file(\"Leyendas, cuentos y poemas\", \"https://www.gutenberg.org/files/10814/10814-8.txt\")\n","text = open(path, \"rb\").read().decode(encoding=\"ISO-8859-1\") # The encoding is found in the book's metadata in Gutemberg\n","print(f\"Leyendas, cuentos y poemas\")\n","print(f\"Length of text: {len(text):,} characters\")\n","print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eK7vrvVC9q8h"},"outputs":[],"source":["# Remove anything before the first sentence of the book.\n","sequence = \"(_Cartas Literarias_)\"\n","\n","# Split the string based on the sequence\n","split_result = text.split(sequence, 1) # splits just 1 time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[1].lstrip()\n","else:\n","    result_string = text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CHQs2oek9xUL"},"outputs":[],"source":["# Remove anything after the last sentence of the book.\n","sequence = \"Á quienes no conozco!\"\n","\n","# Split the string based on the sequence\n","split_result = result_string.split(sequence, 1) # splits just one time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[0]\n","else:\n","    result_string = text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJbXwk4kicGw"},"outputs":[],"source":["# Remove footnotes in English (text inside brackets).\n","\n","# Use regular expressions to remove text inside brackets\n","cleaned_document = re.sub(r'\\[.*?\\]', '', result_string, flags=re.DOTALL)\n","\n","# Print the cleaned document\n","print(cleaned_document)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1696784173050,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"HxlAy9bp91jz","outputId":"de870ad0-bd68-4376-ff06-9098d4ef3144"},"outputs":[{"data":{"text/plain":["str"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["type(cleaned_document)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1696784173050,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"kpbhReV3_JUt","outputId":"43032fea-2fcb-4bcf-a665-738566d66888"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory: /content\n"]}],"source":["# Get the current working directory\n","current_directory = os.getcwd()\n","\n","# Print the current working directory\n","print(\"Current working directory:\", current_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ctmIfS02_TTx"},"outputs":[],"source":["# Save file in the working directory\n","\n","# Specify the file path where you want to save the file\n","file_path = \"gutemberg_cuentos_leyendas.txt\"\n","\n","# Open the file in write mode ('w')\n","with open(file_path, 'w') as file:\n","    # Write the string to the file\n","    file.write(cleaned_document)\n","\n","# The file is automatically closed when the 'with' block exits\n"]},{"cell_type":"markdown","metadata":{"id":"dMCgn1HR0UWd"},"source":["## Doc 2: Obras escogidas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":432,"status":"ok","timestamp":1696784173737,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"Vznyp7bT0bdz","outputId":"560e362c-1d42-4dac-fbc3-652e6a782753"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.gutenberg.org/files/53552/53552-8.txt\n","585523/585523 [==============================] - 0s 1us/step\n","Obras escogidas\n","Length of text: 585,523 characters\n","\n"]}],"source":["path = tf.keras.utils.get_file(\"Obras escogidas\", \"https://www.gutenberg.org/files/53552/53552-8.txt\")\n","text = open(path, \"rb\").read().decode(encoding=\"ISO-8859-1\")\n","print(f\"Obras escogidas\")\n","print(f\"Length of text: {len(text):,} characters\")\n","print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1696784173737,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"se0lHZ6M4BGt","outputId":"505a3334-ce59-432a-850b-1c9feaae1641"},"outputs":[{"name":"stdout","output_type":"stream","text":["b'el monumento erigido al\\r\\npoeta.'\n"]}],"source":["# Original text with new lines\n","original_text = \"el monumento erigido al\\npoeta.\"\n","\n","# Convert new lines to ISO-8859-1 encoding with appropriate newline character\n","iso_8859_1_text = original_text.encode('iso-8859-1').replace(b'\\n', b'\\r\\n')\n","  # replace(b'\\n', b'\\r\\n') replaces the newline character (b'\\n') with the Windows-style newline character (b'\\r\\n').\n","  # Adjust the replacement value according to the desired newline character format.\n","\n","# Print the encoded text\n","print(iso_8859_1_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1696784173737,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"kMXKg6L93pJl","outputId":"09f0e733-458c-4bbf-ea91-d8cd07c2eb71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Substring found!\n"]}],"source":["substring = \"el monumento erigido al\\r\\npoeta.\"\n","\n","if substring in text:\n","    print(\"Substring found!\")\n","else:\n","    print(\"Substring not found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCgEf-s_0bd0"},"outputs":[],"source":["# Remove anything before the first sentence of the book.\n","sequence = \"el monumento erigido al\\r\\npoeta.\"\n","\n","# Split the string based on the sequence\n","split_result = text.split(sequence, 1) # splits just 1 time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[1].lstrip()\n","else:\n","    result_string = text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7oRyN1a2hUx"},"outputs":[],"source":["print(result_string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hz5K7bfm0bd0"},"outputs":[],"source":["# Remove anything after the last sentence of the book.\n","sequence = \"creo que le sucedería lo mismo.\" # Not including the 'Rimas' section.\n","\n","# Split the string based on the sequence\n","split_result = result_string.split(sequence, 1) # splits just one time\n","\n","# Check if the sequence was found in the string\n","if len(split_result) > 1:\n","    result_string = split_result[0]\n","else:\n","    result_string = text\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnmCds8V6_3o"},"outputs":[],"source":["print(result_string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbQ6Hwsy0bd6"},"outputs":[],"source":["# Remove editorial comments (in brackets).\n","\n","# Use regular expressions to remove text inside brackets\n","cleaned_document_2 = re.sub(r'\\[.*?\\]', '', result_string, flags=re.DOTALL) # With re.DOTALL, the dot can match newline characters\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDhVwU5p7OfV"},"outputs":[],"source":["print(cleaned_document_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hx_R90p01IxL"},"outputs":[],"source":["# Remove editorial underscores that denote italics, keep text in between.\n","\n","# Remove underscores using str.replace() method\n","cleaned_document_2 = cleaned_document_2.replace(\"_\", \"\")\n","\n","# Print the cleaned string\n","print(cleaned_document_2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1696784177132,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"RloGWvky0bd6","outputId":"799259e4-6b56-43bf-bad2-10f1d1b74547"},"outputs":[{"data":{"text/plain":["str"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["type(cleaned_document_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1696784177132,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"wbTzRsE60bd6","outputId":"fc26c415-bc01-4397-b676-4afdc205782e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current working directory: /content\n"]}],"source":["# Get the current working directory\n","current_directory = os.getcwd()\n","\n","# Print the current working directory\n","print(\"Current working directory:\", current_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFN2DfL50bd6"},"outputs":[],"source":["# Save file in the working directory to get path\n","\n","# Specify the file path where you want to save the file\n","file_path = \"gutemberg_obras_escogidas.txt\"\n","\n","# Open the file in write mode ('w')\n","with open(file_path, 'w') as file:\n","    # Write the string to the file\n","    file.write(cleaned_document_2)\n","\n","# The file is automatically closed when the 'with' block exits\n"]},{"cell_type":"markdown","metadata":{"id":"2tOO8Aan1qeI"},"source":["## Join both datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1696784177132,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"frhuj87j8TlK","outputId":"8e40e972-847e-4777-f371-f64927aa4be7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Text file created successfully.\n"]}],"source":["# Two strings to join\n","string1 = cleaned_document\n","string2 = cleaned_document_2\n","\n","# Join the strings together\n","joined_string = string1 + string2\n","\n","# Specify the file path where you want to create the text file\n","file_path = \"gutemberg_joined.txt\"\n","\n","# Open the file in write mode and write the joined string\n","with open(file_path, 'w') as file:\n","    file.write(joined_string)\n","\n","print(\"Text file created successfully.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1696784177132,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"O38V3QOw-OiM","outputId":"2250c362-32e6-4c42-8985-e42b290e5a15"},"outputs":[{"name":"stdout","output_type":"stream","text":["The total length of both documents is 750699 characters.\n"]}],"source":["print('The total length of both documents is {} characters.'.format(len(joined_string)))"]},{"cell_type":"markdown","metadata":{"id":"oSim_yAlDeVB"},"source":["# Finetuning gpt2-spanish"]},{"cell_type":"markdown","metadata":{"id":"s82xSUaIEgul"},"source":["## Setup to save model in Gdrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJUe60eWDdaQ"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"u8IRRtgyD03N"},"outputs":[],"source":["!ls /content/gdrive"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"9Ts_23-tE3VE"},"outputs":[],"source":["import os\n","DATADIR = os.path.join('/content/gdrive', 'My Drive', 'XXX', 'XXX', 'XXX') # Replace with your Gdrive folder path"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"gH1tXGkmGhQA"},"outputs":[],"source":["DATADIR"]},{"cell_type":"markdown","metadata":{"id":"3ffvtbcw9Sk7"},"source":["## About the model"]},{"cell_type":"markdown","metadata":{"id":"Q-prsHdb_9Dd"},"source":["[**DeepESP/gpt2-spanish**](https://huggingface.co/DeepESP/gpt2-spanish?text=Quisiera+saber+que+va+a+suceder)\n","\n","License: [mit](https://choosealicense.com/licenses/mit/)\n","\n","Why is it a good fit for this project?\n","\n","* It was trained on literary text, the field of our writer.\n","* The tokenizer was trained from scratch with the Spanish corpus, to capture the morphosyntactic differences between English and Spanish."]},{"cell_type":"markdown","metadata":{"id":"dSMqbkeRFeiB"},"source":["## Finetuning"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"ML_AknJCeJzA"},"outputs":[],"source":["# Load model directly with Hugging Face Auto Classes\n","from transformers import AutoTokenizer, AutoModelForCausalLM"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"TYd4rwfp4nM-"},"outputs":[],"source":["# Constants\n","MODEL_NAME = \"gpt2-spanish\"\n","TRAIN_FILE = \"gutemberg_joined.txt\"\n","TOKENIZER_FILE = \"tokenizer.json\"\n","OUTPUT_DIR = DATADIR # Going to Gdrive"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"xIeSXrrV4pcW"},"outputs":[],"source":["# Load the tokenizer and model\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"DeepESP/gpt2-spanish\")\n","model = AutoModelForCausalLM.from_pretrained(\"DeepESP/gpt2-spanish\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"I1dF6Rau5Ay4"},"outputs":[],"source":["# Prepare the dataset\n","train_dataset = TextDataset(\n","    tokenizer = tokenizer,\n","    file_path = TRAIN_FILE,\n","    block_size = 128\n",")\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer = tokenizer,\n","    mlm = False\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1698008532522,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"U9NuiqX0VDCZ"},"outputs":[],"source":["# Define training arguments and start fine-tuning\n","training_args = TrainingArguments(\n","    output_dir = OUTPUT_DIR,\n","    overwrite_output_dir = False,\n","    per_device_train_batch_size = 8,\n","    num_train_epochs = 1,\n","    save_steps = 10_000,\n","    save_total_limit = 2,\n",")\n","\n","trainer = Trainer(\n","    model = model,\n","    args = training_args,\n","    data_collator = data_collator,\n","    train_dataset = train_dataset,\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"nqcdQaVsL2ND"},"source":["## Save finetuned model"]},{"cell_type":"markdown","metadata":{"id":"yZyUIJxxMK97"},"source":["From [How to save our model to google Drive and reuse it](https://medium.com/@ml_kid/how-to-save-our-model-to-google-drive-and-reuse-it-2c1028058cb2)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1698008532523,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"LTgcXx42LUJI"},"outputs":[],"source":["model_save_name = 'gpt2-spanish_Becquer-joined.pt'\n","path = DATADIR\n","torch.save(model.state_dict(), path)"]},{"cell_type":"markdown","metadata":{"id":"7wDrqEKVFZ73"},"source":["## Use model for text generation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1698008532523,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"KVWYeD9lSbKD"},"outputs":[],"source":["# Save finetuning files\n","model.save_pretrained(OUTPUT_DIR)\n","\n","print(f\"Model fine-tuned and saved to {OUTPUT_DIR}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1698008532523,"user":{"displayName":"Yanett Cepeda","userId":"15324703321502799411"},"user_tz":420},"id":"TKZbpkjgSb4p"},"outputs":[],"source":["prompt = \"Será verdad que\"  # Change this to your desired starting prompt\n","max_length = 150  # Change this to desired output length\n","\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","input_ids = input_ids.to(\"cuda\")\n","\n","output = model.generate(input_ids, max_length=max_length, temperature=0.7)\n","output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(output_text)\n"]},{"cell_type":"markdown","metadata":{"id":"72NP9Wi2Hwe8"},"source":["<a name=\"#conclusion\"></a>\n","# Conclusion"]},{"cell_type":"markdown","metadata":{"id":"TGlxZD8lHnwL"},"source":["The model was finetuned successfully, but it generates repetitive nonsense--no resemblance to the writing style of our author.\n","\n","For improvements and fixes to the output, see `Decoding_methods-gpt2_finetuned.ipynb`, where I use different decoding methods for language generation with Transformers."]},{"cell_type":"markdown","metadata":{"id":"6VM8XgpusfbB"},"source":["## Output example"]},{"cell_type":"markdown","metadata":{"id":"ZH1QjkJZJG_Q"},"source":["Prompt:\n","`\"Será verdad que...\"`\n","\n","Output:\n","`Será verdad que no se ha de\n","hablar de la verdad, y que no se ha de\n","haber de la verdad, y que no se ha de\n","haber de la verdad, sino de la verdad, y que\n","se ha de creer que no se ha de creer en nada, y que\n","se ha de creer que no se ha de creer en nada, y que\n","se ha de creer en algo, y que no se ha de creer en nada, y que\n","se ha de creer en algo, y que no se ha de creer en nada, y que\n","se ha de creer en algo, y que no se ha de creer en nada, y que\n","se ha de creer en algo, y que se`"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1aYS-er_ke6CX454Hx_emodd4OGpOLXG2","timestamp":1695940394581}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
